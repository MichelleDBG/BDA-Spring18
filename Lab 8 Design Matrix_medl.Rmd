---
title: "Lab 8 - design matrix"
output:
  html_document: default
  html_notebook: default
  pdf_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 6
---

This lab offers practice with design matrices and an introduction to summaries of the lm() function. Let's work with the spider data, described in 5.8

```{r}
spider <- read.csv("P:/My Documents/BDA_Spring2018/spider_wolff_gorb_2013.csv")
```

***

**Q1.** Create the design matrix for modeling the effect of different leg sets on the observed friction coefficient. Provide only the R code for doing this (it's a long matrix), and write a few sentences to describe the components of the matrix (i.e. say what comprise the rows, columns, and values in each cell).
```{r}
spider.dm <- model.matrix(~factor(spider$leg)) #took out "-1" as a boolean 
spider.dm[c(67:70,99:100,240:241),] #subset of the design matrix
```
    This design matrix sets the intercept to 1 for all rows (individuals, samples). For the folloiwng columns, the value in a cell is 1 when that individual (row) has the friction value for the corresponding leg pair in the appropriate column. Column 1 ("Intercept") has a 1 in every row. The second column has a 1 in a row with a corresponding "L2" in the row of the spider dataframe "leg" column and a 0 in all other rows. Likewise, column 3 and 4 of the design matrix only has 1s in rows for which the spider data frame leg column is "L3" or "L4" respectivly.  
    

**Q2.** How many parameters in this design? Explain what they are and what information they provide, referencing the design matrix you produced in Q1. Then provide the parameter matrix.

There are four parameters in the leg design. The inercept, $\beta_0$, is the mean of friction from L1 leg pair. Then $\beta_1$ is the offset from the intercept to the mean of L2, $\beta_0$ + $\beta_1$. The third parameter, $\beta_2$, is the effect size of L3 from L1 ($\beta_0$ + $\beta_2$ = mean friction of L3). The final parameter is $\beta_3$ which is the effect size of L4 (the offset from L1 to L4).   
$$
{\left(\begin{array}{cc}
  \beta_{0}\\
  \beta_{1}\\
  \beta_{2}\\
  \beta_{3}
  \end{array}\right)
}
$$


***

lm() handles all that linear algebra we did in lab last week and in class this week. It outputs a lot of information. Let's take a look at a model for the effect of pushing vs. pulling (movement type) on the friction coefficient.

```{r}
modelfit <- lm(friction~type, data=spider)
str(modelfit)
```

Lots of results. The first few are the most commonly used. Coefficients are the $\hat{\beta}$ of course. Residuals are the $\epsilon$. The data, of course, provide the X and Y. So why all that other stuff? Much of it is beyond the scope of this course; we'll just look at summaries using the summary.lm() function. Note: can also just use summary() and R will recognize that it's an lm object...

```{r}
summary(modelfit)
```

Nice and tidy. First, R reminds us which model we fit. Next it provides the 5-point summary for the distribution of the $\epsilon_i$. Next, it gives the $\hat{\beta_i}$, associated uncertainties, and the results for a t-test of the null hypothesis that the given coefficient value is equal to zero. It next provides the standard error of the distribution of $\epsilon_i$ (and the denominator value so that a person could compute the standard deviation instead). Next is the $R^2$ and adjusted $R^2$. We can peek at the summary.lm function to figure out how $R^2$ and adjusted $R^2$ are computed:

1) $R^2 = \frac{MSS}{(MSS + RSS)}$
2) $adj.R^2 = 1 - (1 - r.squared) * \frac{(n - df.int)}{rdf}$

MSS is the mean sum of squares. RSS is the residual sum of squares. df.int is 1 if an intercept term is estimated, 0 if not. rdf is the residual degrees of freedom (N-p).

I inlcude this only because students always ask about the adjusted $R^2$. More generally, $R^2$ is a slipperly statistic, and it's often times much less useful that it's touted as being. We'll discuss the computations and interpretations in class. Some will benefit from this, others not so much. And that's OK.

Finally, the F statistic is the test statistic for all linear models. It is used to test the null hypothesis that the data were generated by a random process centered on a single value for the mean, and variance $\sigma^2$. We'll cover that in more detail later.

***

**Q3.** Given the output for the linear model presented above - for the effect of movement type (push v. pull) on the friction coefficient - what is the mean value of the friction coefficient for the spider legs that were pushing?   
```{r}
mean(spider$friction[spider$type=="push"])
lm1 <- summary(modelfit)
signif(lm1$coefficients[1]+lm1$coefficients[2],2)
1.21121+(-0.77901)
```
   The legs that were pushing have a mean value of 0.43. This is the intercept plus the effect size of the type push estimate. 

**Q4.** Fit the linear model for the design you provided in Q1 and write down the value for the mean friction coefficient for each of the 4 leg sets.   
```{r}
spider.lm <- lm(friction~leg,data=spider)
spider.lm.forceintzero <- lm(friction~leg+0,data=spider) #boolean design

coefs <- c("L1","L2","L3","L4")
coefs.full <- expand.grid(c("pull","push"),c("L1","L2","L3","L4"))

summary(spider.lm)


#ctrl+shift+c
#for(i in 1:4){
#   print(paste("Mean friction coefficient for ", coefs[i], ": mean = ",
#             round(mean(spider$friction[spider$leg==coefs[i]]),2), #L1
#             ", and when intercept is forced through zero, beta_", i," = ",
#             round(spider.lm.forceintzero$coefficients[i],2), sep=""))
#   if(i>1){
#     print(paste("  *Effect size for coefficient ", coefs[i], ", beta*_",
#                 i-1, " = ",
#                 round(spider.lm$coefficients[i], 2), sep=""))
#   }
# }

for(i in 1:4){
  if(i==1){
    print(paste("The mean friction coefficient for", coefs[i], "is beta_0 =",
                signif(spider.lm$coefficients[1],2),sep=" "))
  } else {
    print(paste("The mean friction coefficient for ", coefs[i], " is beta_0 + beta_",
                i-1, " = ", signif(spider.lm$coefficients[1]+
                                     spider.lm$coefficients[i],2), sep=""))
  }
}
```


**Q5.** Given what you understand of the data, does the way we've been fitting the model seem to make intuitive sense, or should we be forcing the intercept to be zero? Explain.      
  Forcing the intercept to be zero makes the $\hat{\beta}$ be the offset from 0, the mean of each instead of the effect size in comparison to the baseline value of the first factor, L1. When there is not a level that is the control, as in this case, then forcing the intercept to zero makes sense. In caseswhen  we are interested in the effect size or difference from a baseline value ("L1"), i.e. treatments compared to a control mean then the way we fit the model in Q1 is approporiate.  


***

Finally, let's consider a multi-variate model (two-way ANOVA) for the additive effects of leg set and movement type on the friction coefficient. We'll fit the simple main effects model without and interaction.


```{r}
twowayFit <- lm(friction ~ type + leg, data = spider)
summary(twowayFit)
```

***
```{r,echo=FALSE}
tail(model.matrix(spider$friction~spider$leg+spider$type+0),20)

tail(model.matrix(spider$friction~spider$leg+spider$type),20)
```

**Q6.** Write the sample space for this experimental design. Hint: this will be the set of all possible "states" for leg set and movement type that can be observed in the experiment. It may help to look at the actual design matrix you developed in Q1.   

    
    The sample space of both leg set and movement type contains the following 8 rows:  
```{r}
expand.grid(c("pull","push"),c("L1","L2","L3","L4"))
``` 


**Q7.** Use that sample space to interpret each of the $\hat{\beta_i}$. That is, write down the experimental condition for the intercept, for typepush, legL2, etc.    
```{r}
leg<-factor(c(rep("L1",2),rep("L2",2),rep("L3",2),rep("L4",2)))
type<-factor(rep(c("pull","push"),4))

data.frame(leg,type)

lm(friction~leg+type -1, data=spider)
aggregate(friction~type+leg, mean, data=spider)

# effect size
matrixmodel.q1 <- model.matrix(~ type+leg)
matrixmodel.q1
lm.multi <- lm(friction~leg+type, data=spider)
betavec <- lm.multi$coefficients
exp.cond.q1 <- matrixmodel.q1 %*% betavec

# means forced zero for type
matrixmodel <- model.matrix(~ type + leg -1)
matrixmodel
lm.multi.for0 <- lm(friction~type + leg -1, data=spider)
betavec.for0 <- lm.multi.for0$coefficients
exp.cond <- matrixmodel %*% betavec.for0

# means forced zero for leg
matrixmodel.swap <- model.matrix(~ leg +type -1)
matrixmodel.swap
lm.multi.for0.1 <- lm(friction~leg+type -1, data=spider)
betavec.for0.1 <- lm.multi.for0.1$coefficients
exp.cond <- matrixmodel.swap %*% betavec.for0.1

for(i in 1:8){
    print(paste("                             Experimental condition for ", leg[i], type[i],
                "is", signif(exp.cond.q1[i],2)))
  print(paste("Experimental condition when intercept forced through zero", 
              leg[i], type[i],
              "is", signif(exp.cond.q1[i],2)))
}
```

   The experimental condition for the model is:   
      1 - L1 pull is $\beta_0$   
      2 - L1 push is $\beta_0$ + $\beta_1$    
      3 - L2 pull is $\beta_0$ + $\beta_2$    
      4 - L2 push is $\beta_0$ + $\beta_1$ + $\beta_2$   
      5 - L3 pull is $\beta_0$ + $\beta_3$   
      6 - L3 push is $\beta_0$ + $\beta_1$ + $\beta_3$    
      7 - L4 pull is $\beta_0$ + $\beta_4$  
      8 - L4 pull is $\beta_0$ + $\beta_1$ + $\beta_4$   
 
   When the leg set is the intercept set to zero, the experimental condition should be:  
      1 - L1 pull is $\beta_1$     
      2 - L1 push is $\beta_2$    
      3 - L2 pull is $\beta_1$ + $\beta_3$     
      4 - L2 push is $\beta_2$ + $\beta_3$   
      5 - L3 pull is $\beta_1$ + $\beta_4$     
      6 - L3 push is $\beta_2$ + $\beta_4$       
      7 - L4 pull is $\beta_1$ + $\beta_5$    
      8 - L4 pull is $\beta_2$ + $\beta_5$    


   But the matrix model with the type intercept set to zero calculates:       
      1 - L1 pull is $\beta_1$     
      2 - L1 push is $\beta_1$ + $\beta_5$     
      3 - L2 pull is $\beta_2$          
      4 - L2 push is $\beta_2$ + $\beta_5$   
      5 - L3 pull is $\beta_3$         
      6 - L3 push is $\beta_3$ + $\beta_5$       
      7 - L4 pull is $\beta_4$            
      8 - L4 pull is $\beta_4$ + $\beta_5$      
  

   Can the intercept of only one variable be set to zero and the other is an effect size. Why is that? Can more than one be forced to zero?    

   This full design matrix is not boolean (missing the "+0" or "-1"). In this case the intercept, $\beta_0$, is the mean friction of L1 when pulling. The second column, $\beta_1$, is the effect size of pushing so mean pushing friction of L1 is $\beta_0$ + $\beta_1$. The parameters $\beta_j$ (j = 3-5) are the offset of leg set friction for each leg (L2 to L4) from L1. Adding $\beta_0$ + $\beta_1$ to any of these will give the effect size of pushing to each leg pair.     
$$
{\left(\begin{array}{cc}
  \beta_{0}\\
  \beta_{1}\\
  \beta_{2}\\
  \beta_{3}\\
  \beta_{4}
  \end{array}\right)
}
$$