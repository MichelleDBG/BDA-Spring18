---
title: "Lab 8 - design matrix"
output:
  pdf_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 6
  html_notebook: default
  html_document: default
---

This lab offers practice with design matrices and an introduction to summaries of the lm() function. Let's work with the spider data, described in 5.8

```{r}
spider <- read.csv("P:/My Documents/BDA_Spring2018/spider_wolff_gorb_2013.csv")
```

***

**Q1.** Create the design matrix for modeling the effect of different leg sets on the observed friction coefficient. Provide only the R code for doing this (it's a long matrix), and write a few sentences to describe the components of the matrix (i.e. say what comprise the rows, columns, and values in each cell).
```{r}
spider.dm <- model.matrix(~factor(spider$leg) -1) #as a boolean 
spider.dm[c(67:70,99:100,240:241),] #subset of the design matrix
```
    This design matrix acts as a boolean matrix setting the value in a cell to 1 when that individual (row) has the friction value for the corresponding leg pair in the appropriate column. Column 1 ("L1") has a 1 in rows with a cooresponding "L1" in the row of the spider data frame leg column and a 0 in all other rows. Likewise, column 2 of the design matrix only has 1s in rows for which the spider data frame leg column is "L2". This pattern is continued for "L3" and "L4".  


#Take out!!!   
   If you are asking for the effect of different leg sets and whether the legs are pushing or pulling, then the design matrix becomes:    
```{r}
spider.full.dm <- model.matrix(friction ~ factor(leg) + factor(type), data=spider)
spider.full.dm[c(1:2,67:70,80:85,99:100,240:241,nrow(spider)),] #subset of the design matrix
```
   

**Q2.** How many parameters in this design? Explain what they are and what information they provide, referencing the design matrix you produced in Q1. Then provide the parameter matrix.
   
#######   
Change it to not offset, they are all the mean. 
There are four parameters in the leg design. The first column, $\beta_1$, is the mean of friction from L1 leg pair. $\beta_2$ is the offset from the intercept to the mean of L2. legL3, $\beta_3$, is the effect size of L3 from L1 ($\beta_1$ + $\beta_3$ = mean friction of L3). The final parameter is $\beta_4$ which is the effect size of L4 (the offset from L1 to L4).   
$$
{\left(\begin{array}{cc}
  \beta_{1}\\
  \beta_{2}\\
  \beta_{3}\\
  \beta_{4}
  \end{array}\right)
}
$$

   This full design matrix is not boolean (missing the "+0"). In this case the Intercept, $\beta_0$, is the mean friction of L1 when pulling. The last column, $\beta_4$, is the effect size of pushing so mean pushing friction of L1 is $\beta_0$ + $\beta_4$. The parameters $\beta_j$ (j = 1-3) are the offset of pulling friction for each leg (L2 to L4). Additionally adding $\beta_4$ to any of these will give the effect size of pushing to each leg pair.     
$$
{\left(\begin{array}{cc}
  \beta_{0}\\
  \beta_{1}\\
  \beta_{2}\\
  \beta_{3}\\
  \beta_{4}
  \end{array}\right)
}
$$

***

lm() handles all that linear algebra we did in lab last week and in class this week. It outputs a lot of information. Let's take a look at a model for the effect of pushing vs. pulling (movement type) on the friction coefficient.

```{r}
modelfit <- lm(friction~type, data=spider)
str(modelfit)
```

Lots of results. The first few are the most commonly used. Coefficients are the $\hat{\beta}$ of course. Residuals are the $\epsilon$. The data, of course, provide the X and Y. So why all that other stuff? Much of it is beyond the scope of this course; we'll just look at summaries using the summary.lm() function. Note: can also just use summary() and R will recognize that it's an lm object...

```{r}
summary(modelfit)
```

Nice and tidy. First, R reminds us which model we fit. Next it provides the 5-point summary for the distribution of the $\epsilon_i$. Next, it gives the $\hat{\beta_i}$, associated uncertainties, and the results for a t-test of the null hypothesis that the given coefficient value is equal to zero. It next provides the standard error of the distribution of $\epsilon_i$ (and the denominator value so that a person could compute the standard deviation instead). Next is the $R^2$ and adjusted $R^2$. We can peek at the summary.lm function to figure out how $R^2$ and adjusted $R^2$ are computed:

1) $R^2 = \frac{MSS}{(MSS + RSS)}$
2) $adj.R^2 = 1 - (1 - r.squared) * \frac{(n - df.int)}{rdf}$

MSS is the mean sum of squares. RSS is the residual sum of squares. df.int is 1 if an intercept term is estimated, 0 if not. rdf is the residual degrees of freedom (N-p).

I inlcude this only because students always ask about the adjusted $R^2$. More generally, $R^2$ is a slipperly statistic, and it's often times much less useful that it's touted as being. We'll discuss the computations and interpretations in class. Some will benefit from this, others not so much. And that's OK.

Finally, the F statistic is the test statistic for all linear models. It is used to test the null hypothesis that the data were generated by a random process centered on a single value for the mean, and variance $\sigma^2$. We'll cover that in more detail later.

***

**Q3.** Given the output for the linear model presented above - for the effect of movement type (push v. pull) on the friction coefficient - what is the mean value of the friction coefficient for the spider legs that were pushing?   
```{r}
mean(spider$friction[spider$type=="push"])
1.21121+(-0.77901)
```
   The legs that were pushing have a mean value of 0.43. This is the intercept plus the effect size of the type push estimate. 

**Q4.** Fit the linear model for the design you provided in Q1 and write down the value for the mean friction coefficient for each of the 4 leg sets.   
```{r}
lm(friction~leg,data=spider)

lm(friction~leg+0,data=spider) # My first design matrix

spider.lm <- lm(friction~leg,data=spider)
spider.lm.forceintzero <- lm(friction~leg+0,data=spider)

coefs <- c("L1","L2","L3","L4")
coefs.full <- expand.grid(c("pull","push"),c("L1","L2","L3","L4"))


for(i in 1:4){
  print(paste("Mean friction coefficient for ", coefs[i], ": mean = ",
            round(mean(spider$friction[spider$leg==coefs[i]]),2), #L1
            ", beta_", i-1," = ",
            round(spider.lm.forceintzero$coefficients[i],2), sep=""))
  if(i>1){
    print(paste("  *Effect size for coefficient ", coefs[i], ", beta_",
                i-1, " = ",
                round(spider.lm$coefficients[i], 2), sep=""))
  }
}


#for(i in 1:5)

```


**Q5.** Given what you understand of the data, does the way we've been fitting the model seem to make intuitive sense, or should we be forcing the intercept to be zero? Explain.  
  Forcing the intercept to be zero makes the $\hat{\beta}$ be the offset from 0, the mean instead of the effect size in comparison to the baseline value of each in comparison to the first parameter. When there is not a level that is the control, then forcing the intercept makes sense. However, in some cases we are interested in the effect size or difference from a baseline value ("L1"), i.e. treatments compared to a control mean. 


***

Finally, let's consider a multi-variate model (two-way ANOVA) for the additive effects of leg set and movement type on the friction coefficient. We'll fit the simple main effects model without and interaction.


```{r}
twowayFit <- lm(friction ~ type + leg, data = spider)
summary(twowayFit)
```

***
```{r,echo=FALSE}
tail(model.matrix(spider$friction~spider$leg+spider$type+0),50)
```

**Q6.** Write the sample space for this experimental design. Hint: this will be the set of all possible "states" for leg set and movement type that can be observed in the experiment. It may help to look at the actual design matrix you developed in Q1.   

    
    The sample space of both leg set and movement type contains the following 8 rows:  
```{r}
expand.grid(c("pull","push"),c("L1","L2","L3","L4"))
``` 


**Q7.** Use that sample space to interpret each of the $\hat{\beta_i}$. That is, write down the experimental condition for the intercept, for typepush, legL2, etc.    
```{r}
leg<-factor(c(rep("L1",2),rep("L2",2),rep("L3",2),rep("L4",2)))
type<-factor(rep(c("pull","push"),4))

data.frame(leg,type)

lm(friction~leg+type -1, data=spider)
aggregate(friction~type+leg, mean, data=spider)

model.matrix(~ type + leg -1)
```

   The experimental condition is:   
      1 - L1 pull is $\beta_1$   
      2 - L1 push is $\beta_1$ + $\beta_2$    
      3 - L2 pull is $\beta_3$    
      4 - L2 push is $\beta_3$ + $\beta_2$   
      5 - L3 pull is $\beta_1$ + $\beta_4$   
      6 - L3 push is $\beta_4$   
      7 - L4 pull is $\beta_4$ + $\beta_2$  
      8 - L4 pull is $\beta_2$ + $\beta_5$   