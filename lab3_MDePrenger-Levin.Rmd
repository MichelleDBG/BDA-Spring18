---
title: "Lab 3 - simulation-based inference"
output:
  html_document: default
  html_notebook: default
  pdf_document:
    fig_caption: yes
    fig_height: 5
    fig_width: 6
---

####*We don't need no stinking t-tables...*

Monte Carlo simulation methods are really useful for generating sampling distributions for cases where we don't know what the sampling distribution will be in the limit - that is, for when we can't write a distribution function in closed form (can be written as area under curve = 1). This lab will explore a number of ways to use simulation for inference in data analysis.

****

#####Randomization tests

One version of a randomization test uses simulation to repeatedly "shuffle" the values for a nominally-scaled explanatory variable and then calculate the statistic of interest as though the shuffled values were correct. In this way, it generates the sampling distribution for your test statistic when the true distribution of the nominal variable is random. In effect, it generates a non-parametric null distribution. Given a specific data set, it's always possible to compute all possible values of the statistic under all possible permutations of the labels for the nominal variable; for this reason, you might also see this procedure called a *permutation test*. Fisher's exact test does this when you have two nominally-scaled variables. This lab is designed to teach simulation principles, so we will illustrate the simulation version of the randomization test for a measurement response variable. This version is also very flexible in terms of the summary statistic that you want to characterize with a randomized sampling distribution - no need to compare means...

Let's use some qPCR data for this example. The design is simple: treatment is a factor of interest, which has two levels on the nominal scale (treatment, control), and gene is the other. We have two genes, one for which we want to quantify expression, and the other a "housekeeping" gene that we use to normalize the expression levels for the gene of interest. The response variable of interest is $\Delta C_t$, which is the difference in expression (estimated as # of PCR cycles for which the measured fluorescence exceed a specified threshold) between the target and housekeeping genes. The data we'll use are from 12 observations of the treatment and 12 observations of the control. Each observation involved measures for both the target and housekeeping gene, so that we end up with a total of 24 measures of $\Delta C_t$. Yuan et al. (2006 BMC Bioinfomatics 7:85) recommend using a t-test to test for differences between the mean $\Delta C_t$ for the control and treatment groups. We'll revisit these data later because the designs usually involve small numbers of replicates and often there are both technical and true (biological) replicates, which will give us some texture later when we discuss pseudoreplication. For now, let's compare the outcomes for a t-test and a randomization test for difference in means.

```{r}
# load the data
qpcr <- data.frame(trt = c(rep("control",12),rep("treatment",12)),
                  dct = c(3.3687,3.4063,3.5066,4.5963,3.7704,3.4906,3.3016,3.7572,3.3607,
                          3.5453,3.6461,3.9351,3.3345,2.9337,3.3349,2.5397,2.6615,2.8767,
                          3.1472,3.2965,2.7206,3.0662,2.7814,2.7741))
# look at the data
#install.packages("sm")
library(sm)
sm.density.compare(qpcr$dct,qpcr$trt,xlab=expression(paste(Delta,C[t])))
legend(4.2,1.4,levels(qpcr$trt),lty=c(1,2),col=c("red","green"))
```

```{r}
# do a 2-sample t-test
t.test(qpcr$dct~qpcr$trt)

# do a randomization test for difference in means
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,mean))
reps <- 10000
rand.diff <- NULL
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,mean))
}
```

```{r}
hist(rand.diff,main="randomized sampling distribution",
     xlab=expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")),
     xlim=c(-1,1))
points(obs.diff,100,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)
abline(v = -.414, col="red")
text(-0.46,1000,"CI: 0.05", srt=90,cex=0.5)
abline(v= -0.956, col="red")
text(-0.99, 1000, "CI 0.95", srt=90, cex=0.5)
pval <- mean(abs(rand.diff)>abs(obs.diff))
pval
```


#####Question 1
a. Does the shape of the density curves justify the use of means as a summary statistic? Explain.
  - The density curve indicates that the means are not normally distributed. There are two peaks (bimodal) in the control and some indication of a second peak in the treatment. There may be more than one process determining the average. 
b. N=12 for each of the two treatments. Is that sample size large enough to do a t-test? Explain.  
  - The sample size is large enough to do a t-test but might not be large enough to describe the mean and standard distriubtion of the average. It is possible if the sample size were larger that the distribution would be more normal and a difference in means would be the approapiate test. If the sample size were smaller, the estimation of the difference in mean would become less peaked (less likely) and the variation around the estimate will grow. The likelihood of a type I error would greatly increase. 
```{r}
# do a randomization test for difference in means
  obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,mean))
  reps <- 10000
  rand.diff <- NULL
  set.seed(30)

rand.diff <- do.call(rbind, lapply(seq(12,2,-2), function(x){
  diffs<-c()
  for(i in 1:reps){
    qpcr.sam <- qpcr[c(sample(1:12, x),
                       sample(13:24, x)),]
    qpcr.sam$randtrt <- sample(qpcr.sam$trt)
    diffs[i] <- diff(tapply(qpcr.sam$dct,qpcr.sam$randtrt,mean))
    }
  diff.out <- data.frame(DiffMean = diffs,SampleSize = x)
  })
  )

library(ggplot2)
ggplot(rand.diff, aes(DiffMean, fill=as.factor(SampleSize)))+
  geom_density(alpha=0.25)+
  theme_bw()+
  xlab(expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")))+
  scale_fill_discrete(name = "Sample Size")+
  geom_text(aes(x=-0.78,y=0.25), label="Obs diff",
            angle=90)+
  geom_vline(aes(xintercept = -0.68))
  
```
c. Evaluate the assumptions for each test and describe the extent to which they are met.   
  - The basic t-test assuptions are not met. The distributions of the treatment and the control samples cannot be expressed as a normal distribution. The permutation test approaches a normal distribution.      
```{r}
hist(rand.diff$DiffMean[rand.diff$SampleSize == 12],
     main="randomized sampling distribution",
     xlab=expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")))
```
      
d. Write some code to carry out a permutation test for the difference in values of a more appropriate summary statistic (given the desitributions of $\Delta C_t$ for the treatment and control)    
```{r}
#The peak, max value?
# do a randomization test for difference in means
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,max))
reps <- 10000
rand.diff <- NULL
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,max))
}
hist(rand.diff,main="randomized sampling distribution",
     xlab=expression(paste("Difference in maximum ",Delta,C[t]," (treatment - control)")))
points(obs.diff,0,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)
pval <- mean(abs(rand.diff)>abs(obs.diff))
pval
#No, terrible bimodal strange behaviour. 
```

```{r}
#The peak, mean value?
# do a randomization test for difference in means to compare to the median
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,mean))
reps <- 10000
rand.diff <- NULL
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,mean))
}
hist(rand.diff,main="randomized sampling distribution",
     xlab=expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")))
points(obs.diff,0,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)


#The peak, median value?
# do a randomization test for difference in median
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,median))
reps <- 10000
rand.diff <- NULL
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,median))
}
hist(rand.diff,main="randomized sampling distribution",
     xlab=expression(paste("Difference in median ",Delta,C[t]," (treatment - control)")))
points(obs.diff,0,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)
pval <- mean(abs(rand.diff)>abs(obs.diff))
pval

```

  - 95% CI   
```{r}
# do a randomization test for difference in medians
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,median))
reps <- 10000
set.seed(30)

diffs <- sapply(1:reps, function(sim){
  median(sample(qpcr$dct, 12, replace=TRUE))-
    median(sample(qpcr$dct, 12, replace=TRUE))
})   

    #Is the obs.diff within the upper and lower quatiles of the rand.diff distribution?
    #There will be a few NAs because of the next when sampled fewer than 2 of
diffs.matrix <- matrix(diffs, 100)
hist(diffs)

# My own made up way:
CI95 <- do.call(rbind,lapply(1:100,function(row){
  data.frame(CI95=quantile(diffs.matrix[row,],0.95),
             CI05=quantile(diffs.matrix[row,],0.05))
}))
# Try following page 41 in the book!
se.dist <- sapply(1:100, function(row){
  sd(diffs.matrix[row,]/sqrt(length(diffs.matrix[row,]))) #it's 100, a 100x100 matrix 
})
hist(se.dist)

#95% of the time contain $\mu$ - Not quite the quantile...
mu <- mean(diffs)
mean(CI95$CI95>mu)
mean(CI95$CI05<mu)
# Right, give a normal distribution of the 0.05% on either tail (1-0.05/2)
Q <- qnorm(1-0.05/2) #1.959964
interval.dist <- do.call(rbind,lapply(1:100, function(row){
  c(mean(diffs.matrix[row,]-Q*se.dist[row]),mean(diffs.matrix[row,]+Q*se.dist[row]))
}))

plot(seq(-.1,.1,length=100),1:100,type="n",xlab="difference in medians",
     ylab="interval")
abline(v=mean(diffs))
for(i in 1:100){
  covered<- mean(diffs.matrix[i,]) <= interval.dist[i,1] &
    mean(diffs.matrix[i,]) >= interval.dist[i,2]
  color <- ifelse(covered, "red","yellow")
  lines(interval.dist[i,], c(i,i),col=color)
}
```

Lots of wrong answers:
#Want the 95% CI of the observed differences, not of the null, right? 
#CIwidth <- do.call(rbind,lapply(1:100,function(row){
#  sapply(seq(0.5,1,0.1), function(quant){
#    CI.U <- quantile(diffs.matrix[row,],quant)
#    CI.L <- quantile(diffs.matrix[row,],1-quant)
#    out <- CI.U>mu&CI.L<mu
#    out
#  })
#}))

#colMeans(CIwidth)

#hist(diffs,main="randomized sampling distribution",
#     xlab=expression(paste("Difference in median ",Delta,C[t]," (treatment - control)")))
#points(obs.diff,0,cex=1.5,pch=16)
#text(obs.diff,200,"observed",cex = 0.5)
#points(mean(CI95$CI95),0,cex=2)
#points(mean(CI95$CI05),0,cex=2)
#points(quantile(diffs,.6),0,cex=3) #No!!
#points(quantile(diffs,.4),0,cex=3)
```





d. Write a "results" section based on your answers and the most appropriate R output. Justify your reporting decisions.  
  - The difference in median gene expression of this bimodal distribution is greater than expected if there were no effect of treatment. The 95% confidence interval is 

****

#####Nonparametric bootstrap for estimation

Let's continue with the qpcr data from above. Often, qpcr results are given in terms of the fold change in expression for two levels of the treatment variable. For example, we might want to quantify the x-fold decrease in expression for the control vs treatment conditions. To compute this, we first need the
difference in the $\Delta C_t$ for the control and treatment. Let's compute $\Delta\Delta C_t$ as the difference in median $\Delta C_t$ for the control and treatment (usually people take the differnce in the $\Delta C_t$ averages, not the medians. But that's only by convention, so we'll illustrate the flexibility of simulation-based inference.

The measures for QPCR are in log base 2, so to find the expression fold change, we compute $2^{\Delta\Delta C_t}$. The standard method for doing this uses but a single number for a set of experiments. This discards/ignores observed variance. Let's look at a way to use simulation to create a sampling distribution for the expression fold change. I will write the code for generating one such resampled expression fold value. Your task is to complete the code to generate the sampling distribution for that statistic and then report the result. Remember that in this you are not randomizing the treatments, so when you call the sample() function, you want to preserve the trt-dct dependencies (i.e. sample by rows). Don't worry about constraining your resamples to be balanced. We want to characterize the full range of variance. Warning: you might get all "control" values for some bootstrap resamples, which will prevent you from computing the fold change - don't worry about that. Just take another sample.

```{r}
# just the basic function to compute expression fold change
exfc <- 2^diff(tapply(qpcr$dct,qpcr$trt,median))
exfc #difference in median is 0.65 as an expression of fold change 
# we want bootstrapped samples of the same size
# so find n and resample from 1:n to get new indexes
n <- nrow(qpcr) #there are 24 samples or rows
indx <- sample(1:n,n,T) #Want to sample 24 from these 24 with replacement
# put the new sample in an object called boot so you can see it
boot <- qpcr[indx,] #make a new data.frame with the rows selected at random with replacement
tail(boot) #look at the last 6 rows, can see that row 21 and 14 were selected twice (ie. 21.1 and 14.1 row names)
# notice the rownames become decimals to indicate duplicate samples
# compute exfc for the bootstrap sample
exfc.boot <- 2^diff(tapply(boot$dct,boot$trt,median))
exfc.boot #in this null or bootstrapped sample, the fold increase is 0.54

# OK. You should be ready to roll now.
# Just need to generate the bootstrapped sampling distribution...
# Some code to get you started in that direction
reps <- 5000
set.seed(3023)
boot.exfc <- NULL


```


#####Question 2
a. Write a sentence that you might put in a results section to describe the expression fold change estimate (the effect size) and the uncertainty in that estimate (hint: use the quantiles of the sampling ditribution you created). Feel free to also show the sampling distribution if you like. Just be sure to explain it if you do.


****

#####Reporting summary stats and precision

The final example is for a dataset of stable carbon isotope values ($\delta^{13}C$) measured in insect chitin. Isotope values are reported as deviations (in part per thousand) from a known standard, and so use the delta notation. In the case of carbon, most organic material has less of the heavy isotope than the interational standard (pee dee belemnite), so the values are negative.

Insects were collected from the prairies in C4 grassland and C3 cropland habitats. $\delta^{13}C$ values in plants varies according to differences in water use efficiency; C3 plant $\delta^{13}C$ values tend to be more negative than those for C4 plants. This is because C4 plants respire less than C3 pants, so carbon metabolism in C4 recycles more of the heavy isotope $^{13}C$ than in C3 plants. You want to report something like the average of the isotope values at your study site so that you can compare it to previously published carbon isotope values from other sites.

So the goal is to decide how best to summarize your data in a publication. The code chunk below reads in the data and shows the histogram. The data file "carbon.csv" is posted on canvas. Your task is to write additional code to help you summarize the distribution. You must use the data to calculate summary statistics and/or for parametric simulation or bootstrapping to produce confidence intervals.

```{r}
samp <- read.csv("P:/My Documents/BDA_Spring2018/carbon.csv")
hist(samp$d13C, main="Sample distribution", xlab = expression(paste(delta^13,"C")))

```

#####Question 3
a. What summary statistic(s) would you use to describe the distribution here? Justify your choices.
b. Can you use simulation-based methods to generate a sampling distribution for your summary statistic?