---
title: "Lab 3 - simulation-based inference"
output:
  html_document: default
  html_notebook: default
  pdf_document:
    fig_caption: yes
    fig_height: 5
    fig_width: 6
---

####*We don't need no stinking t-tables...*

Monte Carlo simulation methods are really useful for generating sampling distributions for cases where we don't know what the sampling distribution will be in the limit - that is, for when we can't write a distribution function in closed form (can be written as area under curve = 1). This lab will explore a number of ways to use simulation for inference in data analysis.

****

#####Randomization tests

One version of a randomization test uses simulation to repeatedly "shuffle" the values for a nominally-scaled explanatory variable and then calculate the statistic of interest as though the shuffled values were correct. In this way, it generates the sampling distribution for your test statistic when the true distribution of the nominal variable is random. In effect, it generates a non-parametric null distribution. Given a specific data set, it's always possible to compute all possible values of the statistic under all possible permutations of the labels for the nominal variable; for this reason, you might also see this procedure called a *permutation test*. Fisher's exact test does this when you have two nominally-scaled variables. This lab is designed to teach simulation principles, so we will illustrate the simulation version of the randomization test for a measurement response variable. This version is also very flexible in terms of the summary statistic that you want to characterize with a randomized sampling distribution - no need to compare means...

Let's use some qPCR data for this example. The design is simple: treatment is a factor of interest, which has two levels on the nominal scale (treatment, control), and gene is the other. We have two genes, one for which we want to quantify expression, and the other a "housekeeping" gene that we use to normalize the expression levels for the gene of interest. The response variable of interest is $\Delta C_t$, which is the difference in expression (estimated as # of PCR cycles for which the measured fluorescence exceed a specified threshold) between the target and housekeeping genes. The data we'll use are from 12 observations of the treatment and 12 observations of the control. Each observation involved measures for both the target and housekeeping gene, so that we end up with a total of 24 measures of $\Delta C_t$. Yuan et al. (2006 BMC Bioinfomatics 7:85) recommend using a t-test to test for differences between the mean $\Delta C_t$ for the control and treatment groups. We'll revisit these data later because the designs usually involve small numbers of replicates and often there are both technical and true (biological) replicates, which will give us some texture later when we discuss pseudoreplication. For now, let's compare the outcomes for a t-test and a randomization test for difference in means.

```{r, echo=FALSE, warning=FALSE}
# load the data
qpcr <- data.frame(trt = c(rep("control",12),rep("treatment",12)),
                  dct = c(3.3687,3.4063,3.5066,4.5963,3.7704,3.4906,3.3016,3.7572,3.3607,
                          3.5453,3.6461,3.9351,3.3345,2.9337,3.3349,2.5397,2.6615,2.8767,
                          3.1472,3.2965,2.7206,3.0662,2.7814,2.7741))
# look at the data
#install.packages("sm")
library(sm)
sm.density.compare(qpcr$dct,qpcr$trt,xlab=expression(paste(Delta,C[t])))
legend(4.2,1.4,levels(qpcr$trt),lty=c(1,2),col=c("red","green"))
```

```{r}
# do a 2-sample t-test
t.test(qpcr$dct~qpcr$trt)

# do a randomization test for difference in means
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,mean))
reps <- 10000
rand.diff <- NULL

startfor <- Sys.time()
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,mean))
}
endfor<-Sys.time()
startfor-endfor
```

```{r, echo=FALSE}
hist(rand.diff,main="randomized sampling distribution",
     xlab=expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")),
     xlim=c(-1,1))
points(obs.diff,100,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)
abline(v = -.414, col="red")
text(-0.46,1000,"CI: 0.05", srt=90,cex=0.5)
abline(v= -0.956, col="red")
text(-0.99, 1000, "CI 0.95", srt=90, cex=0.5)
pval <- mean(abs(rand.diff)>abs(obs.diff))
pval
```


#####Question 1
a. Does the shape of the density curves justify the use of means as a summary statistic? Explain.
  - The density curve indicates that the data distributions are not normally distributed. There are two peaks (bimodal) in the control and some indication of a second peak in the treatment. There may be more than one process determining the average.   
  
b. N=12 for each of the two treatments. Is that sample size large enough to do a t-test? Explain.  
  - The sample size is large enough to do a t-test (n > 2 per group) but might not be large enough to describe the distribution of data or the data is really bimodal and not appropriate for a t-test regardless of sample size. The t-distribution better approximates a normal distribution at the tails given a small sample size when trying to calculate the area under the probabily mass function at or beyond the observed value. If the sample size were smaller, the estimation of the difference in mean would become less peaked (less likely) and the variation around the estimate will grow. The likelihood of a type I error would greatly increase. 
```{r}
# do a randomization test for difference in means
  obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,mean))
  reps <- 10000
  rand.diff <- NULL
  set.seed(30)

rand.diff <- do.call(rbind, lapply(seq(12,2,-2), function(x){
  diffs<-c()
  for(i in 1:reps){
    qpcr.sam <- qpcr[c(sample(1:12, x),
                       sample(13:24, x)),]
    qpcr.sam$randtrt <- sample(qpcr.sam$trt)
    diffs[i] <- diff(tapply(qpcr.sam$dct,qpcr.sam$randtrt,mean))
    }
  diff.out <- data.frame(DiffMean = diffs,SampleSize = x)
  })
  )

library(ggplot2)
ggplot(rand.diff, aes(DiffMean, fill=as.factor(SampleSize)))+
  geom_density(alpha=0.25)+
  theme_bw()+
  xlab(expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")))+
  scale_fill_discrete(name = "Sample Size")+
  geom_text(aes(x=-0.78,y=0.25), label="Obs diff",
            angle=90)+
  geom_vline(aes(xintercept = -0.68))
  
```
    
c. Evaluate the assumptions for each test and describe the extent to which they are met.   
  - The two tests are (1)the t-test comparing the two sample means (treatment vs. control) and (2) the permutation test to create the null distribution. The basic t-test assumes a normal distribution but the sample distribution is bimodal so the mean will not be the appropriate summary statistic but is used in a t-test. The distributions of the treatment and the control samples cannot be expressed as a normal distribution. The permutation test creating the distriubtion of difference in means approaches a normal distribution. However, we can see that the underlying distribution of the samples is not normal so the mean, the summary statistic used to test the null distribution, is not appropriate.         
```{r}
hist(rand.diff$DiffMean[rand.diff$SampleSize == 12],
     main="randomized sampling distribution",
     xlab=expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")))
```
      
d. Write some code to carry out a permutation test for the difference in values of a more appropriate summary statistic (given the desitributions of $\Delta C_t$ for the treatment and control)    
```{r}
#The peak, max value?
# do a randomization test for difference in means
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,max))
reps <- 10000
rand.diff <- NULL
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,max))
}
hist(rand.diff,main="Terrible randomized sampling distribution",
     xlab=expression(paste("Difference in maximum ",Delta,C[t]," (treatment - control)")))
points(obs.diff,0,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)
pval <- mean(abs(rand.diff)>abs(obs.diff))
pval
#No, terrible bimodal strange behaviour. But significant p value :) - no where near the correct statistic. 
```

```{r}
#The peak, mean value?
# do a randomization test for difference in means to compare to the median
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,mean))
reps <- 10000
rand.diff <- NULL
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,mean))
}
hist(rand.diff,main="Inappropriate randomized sampling distribution",
     xlab=expression(paste("Difference in mean ",Delta,C[t]," (treatment - control)")))
points(obs.diff,0,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)


#The peak, median value?
# do a randomization test for difference in median
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,median))
reps <- 10000
rand.diff <- NULL
set.seed(30)
for (i in 1:reps) {
  rindx <- sample(qpcr$trt)
  rand.diff[i] <- diff(tapply(qpcr$dct,rindx,median))
}
hist(rand.diff,main="randomized sampling distribution",
     xlab=expression(paste("Difference in median ",Delta,C[t]," (treatment - control)")))
points(obs.diff,0,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)
pval <- mean(abs(rand.diff)>abs(obs.diff))
pval

```

  - 95% CI   
```{r}
# do a randomization test for difference in medians
obs.diff <- diff(tapply(qpcr$dct,qpcr$trt,median))
reps <- 10000
set.seed(30)

diffs <- sapply(1:reps, function(sim){
  median(sample(qpcr$dct, 12, replace=TRUE))-
    median(sample(qpcr$dct, 12, replace=TRUE))
})   

    #Is the obs.diff within the upper and lower quatiles of the rand.diff distribution?
    #There will be a few NAs because of the next when sampled fewer than 2 of
diffs.matrix <- matrix(diffs, 100)
hist(diffs)

# My own made up way:
CI95 <- do.call(rbind,lapply(1:100,function(row){
  data.frame(CI95=quantile(diffs.matrix[row,],0.95),
             CI05=quantile(diffs.matrix[row,],0.05))
}))
# Try following page 41 in the book!
se.dist <- sapply(1:100, function(row){
  sd(diffs.matrix[row,]/sqrt(length(diffs.matrix[row,]))) #it's 100, a 100x100 matrix 
})
hist(se.dist)

#95% of the time contain $\mu$ - Not quite the quantile...
mu <- mean(diffs)
mean(CI95$CI95>mu)
mean(CI95$CI05<mu)
# Right, give a normal distribution of the 0.05% on either tail (1-0.05/2)
Q <- qnorm(1-0.05/2) #1.959964
interval.dist <- do.call(rbind,lapply(1:100, function(row){
  c(mean(diffs.matrix[row,]-Q*se.dist[row]),mean(diffs.matrix[row,]+Q*se.dist[row]))
}))

plot(seq(-.1,.1,length=100),1:100,type="n",xlab="difference in medians",
     ylab="interval")
abline(v=mean(diffs))
for(i in 1:100){
  covered<- obs.diff <= interval.dist[i,2] &
    mean(obs.diff) >= interval.dist[i,1]
  color <- ifelse(covered, 1,2) # Don't know why two colors won't work
  lines(interval.dist[i,], c(i,i),col=color)
}

hist(rand.diff,main="randomized sampling distribution",
     xlab=expression(paste("Difference in median ",Delta,C[t]," (treatment - control)")))
points(obs.diff,0,cex=2.5,pch=16)
text(obs.diff,200,"observed",cex = 0.5)
abline(v=obs.diff-qnorm(1-0.05/2)*mean(se.dist), col="red")
abline(v=obs.diff+qnorm(1-0.05/2)*mean(se.dist), col="red")
#Or maybe you want the largest interval that contains the estimate 95% of the time? 
abline(v=obs.diff-qnorm(1-0.05/2)*max(se.dist), col="black")
abline(v=obs.diff+qnorm(1-0.05/2)*max(se.dist), col="black")

obs.diff-qnorm(1-0.05/2)*max(se.dist)#-0.67
obs.diff+qnorm(1-0.05/2)*max(se.dist) #-0.57

obs.diff-qnorm(1-0.05/2)*mean(se.dist) #-0.66
obs.diff+qnorm(1-0.05/2)*mean(se.dist) #-0.58

mean(diffs)
interval.dist[1,]
```
    
d. Write a "results" section based on your answers and the most appropriate R output. Justify your reporting decisions.  
  - The difference in median gene expression of this bimodal distribution is greater than expected if there were no effect of treatment. The observed difference (-0.62 with a 95%CI of -0.66 to -0.58 red, or -0.67 to -0.58 black) is more extreme than the median of the null, if there were no effect (0.002 95%CI of -0.006 to 0.06). 

****

#####Nonparametric bootstrap for estimation

Let's continue with the qpcr data from above. Often, qpcr results are given in terms of the fold change in expression for two levels of the treatment variable. For example, we might want to quantify the x-fold decrease in expression for the control vs treatment conditions. To compute this, we first need the difference in the $\Delta C_t$ for the control and treatment. Let's compute $\Delta\Delta C_t$ as the difference in median $\Delta C_t$ for the control and treatment (usually people take the differnce in the $\Delta C_t$ averages, not the medians. But that's only by convention, so we'll illustrate the flexibility of simulation-based inference.

The measures for QPCR are in log base 2, so to find the expression fold change, we compute $2^{\Delta\Delta C_t}$. The standard method for doing this uses but a single number for a set of experiments. This discards/ignores observed variance. Let's look at a way to use simulation to create a sampling distribution for the expression fold change. I will write the code for generating one such resampled expression fold value. Your task is to complete the code to generate the sampling distribution for that statistic and then report the result. Remember that in this you are not randomizing the treatments, so when you call the sample() function, you want to preserve the trt-dct dependencies (i.e. sample by rows). Don't worry about constraining your resamples to be balanced. We want to characterize the full range of variance. Warning: you might get all "control" values for some bootstrap resamples, which will prevent you from computing the fold change - don't worry about that. Just take another sample.

```{r}
# just the basic function to compute expression fold change
exfc <- 2^diff(tapply(qpcr$dct,qpcr$trt,median))
exfc #difference in median is 0.65 as an expression of fold change 
# we want bootstrapped samples of the same size
# so find n and resample from 1:n to get new indexes
n <- nrow(qpcr) #there are 24 samples or rows
indx <- sample(1:n,n,T) #Want to sample 24 from these 24 with replacement
# put the new sample in an object called boot so you can see it
boot <- qpcr[indx,] #make a new data.frame with the rows selected at random with replacement
tail(boot) #look at the last 6 rows, can see that row 21 and 14 were selected twice (ie. 21.1 and 14.1 row names)
# notice the rownames become decimals to indicate duplicate samples
# compute exfc for the bootstrap sample
exfc.boot <- 2^diff(tapply(boot$dct,boot$trt,median))
exfc.boot #in this null or bootstrapped sample, the fold increase is 0.54

# OK. You should be ready to roll now.
# Just need to generate the bootstrapped sampling distribution...
# Some code to get you started in that direction
reps <- 5000
set.seed(3023)
boot.exfc <- NULL

for(i in 1:reps){
  indx <- sample(1:n,n,TRUE)
  boot<-qpcr[indx,]
  boot.exfc[i] <- 2^diff(tapply(boot$dct,boot$trt,median)) 
}

hist(boot.exfc, main="Bootstrapped 5,000 reps, red 95%CI")
abline(v=mean(boot.exfc)-qnorm(1-0.05/2)*(sd(boot.exfc)/sqrt(n)),col="red") #0.62
abline(v=mean(boot.exfc)+qnorm(1-0.05/2)*(sd(boot.exfc)/sqrt(n)),col="red") #0.68

boxplot(boot.exfc)
```


#####Question 2
a. Write a sentence that you might put in a results section to describe the expression fold change estimate (the effect size) and the uncertainty in that estimate (hint: use the quantiles of the sampling ditribution you created). Feel free to also show the sampling distribution if you like. Just be sure to explain it if you do.   
  - The x-fold decrease in expression is 0.65 (95%CI 0.62-0.68). All estimated effect sizes show some decrease given that 1 would mean no change in effect.  


****

#####Reporting summary stats and precision

The final example is for a dataset of stable carbon isotope values ($\delta^{13}C$) measured in insect chitin. Isotope values are reported as deviations (in part per thousand) from a known standard, and so use the delta notation. In the case of carbon, most organic material has less of the heavy isotope than the interational standard (pee dee belemnite), so the values are negative.

Insects were collected from the prairies in C4 grassland and C3 cropland habitats. $\delta^{13}C$ values in plants varies according to differences in water use efficiency; C3 plant $\delta^{13}C$ values tend to be more negative than those for C4 plants. This is because C4 plants respire less than C3 pants, so carbon metabolism in C4 recycles more of the heavy isotope $^{13}C$ than in C3 plants. You want to report something like the average of the isotope values at your study site so that you can compare it to previously published carbon isotope values from other sites.

So the goal is to decide how best to summarize your data in a publication. The code chunk below reads in the data and shows the histogram. The data file "carbon.csv" is posted on canvas. Your task is to write additional code to help you summarize the distribution. You must use the data to calculate summary statistics and/or for parametric simulation or bootstrapping to produce confidence intervals.

```{r}
samp <- read.csv("P:/My Documents/BDA_Spring2018/carbon.csv")
hist(samp$d13C, main="Sample distribution", xlab = expression(paste(delta^13,"C")))

```

```{r, echo=FALSE}   
#  - Insects collected from both the cropland and the grassland lumped in one sample distribution. The sampling distribution should indicate whether an insect collection primarily fed on C3 or C4 plants. This would be a ratio... Each observation would indicate the proportion of feeding on C3 vs. C4. Very few fed on just one or the other ($\phi$ = 1) or both equally ($\phi$ = 0.5). Bimodal distribution of likely $\phi$ = 0.75 for C3 and 1-$\phi$ = 0.25 for C4 (with C3 resulting in the peak around -25). An odds ratio of C3/C4 of 3 with $\mu$ ca. -25 and C4/C3 of 1:3 with $\mu$ ca. -14.  
```

#####Question 3
a. What summary statistic(s) would you use to describe the distribution here? Justify your choices.   
  - I have sampled insects from one site, however, that site contains C4 and C3 plants which will each result in a different average carbon isotope value. If insects feed in a random manner in regards to C3 or C4 plants than I would expect a mean isotope value of -19.0 (95%CI -19.1--18.9). The bimodal distribution of the sample implies that insects feed primarily on one plant form or another with an average isotope value of -25.1 (2SD 5.91) for C3 plant feeders and a mean of -13 (2SD 5.76) for C4 plant feeders.      
```{r}
mean(samp$d13C)

sampC3 <- samp$d13C[samp$d13C<mean(samp$d13C)]
2*sd(sampC3) #2.96, 2SD 5.91
sdC3int <- c(mean(sampC3)-2*sd(sampC3),mean(sampC3)+2*sd(sampC3) )
sampC4 <- samp$d13C[samp$d13C>=mean(samp$d13C)]
2*sd(sampC4) #2.88, 5.76
sdC4int <- c(mean(sampC4)-2*sd(sampC4),mean(sampC4)+2*sd(sampC4) )

hist(sampC3,xlim = c(min(samp$d13C),max(samp$d13C)),
     main="C3 feeders (white) and C4 feeders (red). Blue lines = 2SD",
     xlab="Heavy isotope value")
hist(sampC4, add=TRUE, col=rgb(1,0,0,0.5))
lines(sdC3int,c(1,1),col="blue")
lines(sdC4int, c(1,1), col="blue")
```
    

b. Can you use simulation-based methods to generate a sampling distribution for your summary statistic?  
```{r}
samplingmu <- sapply(1:100, function(x){
  median(sample(samp$d13C, nrow(samp),TRUE))
})

n<-length(samplingmu)

hist(samplingmu)
abline(v=mean(samplingmu)-qnorm(1-0.05/2)*(sd(samplingmu)/sqrt(n)),col="red") #-19.1
abline(v=mean(samplingmu)+qnorm(1-0.05/2)*(sd(samplingmu)/sqrt(n)),col="red") #-18.9

```
   
```{r}
sampC3_v2 <- samp$d13C[samp$d13C<mean(samplingmu)]
2*sd(sampC3_v2) #2.96, 2SD 5.91
sdC3int_v2 <- c(mean(sampC3_v2)-2*sd(sampC3_v2),mean(sampC3_v2)+2*sd(sampC3_v2) )
sampC4_v2 <- samp$d13C[samp$d13C>=mean(samplingmu)]
2*sd(sampC4_v2) #2.88, 5.76
sdC4int_v2 <- c(mean(sampC4_v2)-2*sd(sampC4_v2),mean(sampC4_v2)+2*sd(sampC4_v2) )

hist(sampC3_v2,xlim = c(min(samp$d13C),max(samp$d13C)))
hist(sampC4_v2, add=TRUE, col="red")
hist(samplingmu, add=TRUE,col=rgb(1,1,0,0.5))
abline(v=mean(samplingmu)-qnorm(1-0.05/2)*(sd(samplingmu)/sqrt(n)),col="red") #-19.1
abline(v=mean(samplingmu)+qnorm(1-0.05/2)*(sd(samplingmu)/sqrt(n)),col="red") #-18.9
lines(sdC3int_v2,c(1,1),col="blue")
lines(sdC4int_v2, c(1,1), col="blue")
```
